[{"content":"Currently studying Engineering Physics at the University of British Columbia with an avid interest for software engineering, robotics, and embedded systems design. I love problem-solving and the idea of bridging science and math with design to drive positive impact in the community. So far, I\u0026rsquo;ve worked with both clean energy and medtech startups doing firmware and automation engineering.\n","date":"1 January 0001","permalink":"/","section":"","summary":"Currently studying Engineering Physics at the University of British Columbia with an avid interest for software engineering, robotics, and embedded systems design. I love problem-solving and the idea of bridging science and math with design to drive positive impact in the community.","title":""},{"content":"","date":"1 January 0001","permalink":"/tags/c++/","section":"Tags","summary":"","title":"C++"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":" What Is It # A 2nd year Engineering Physics robotics project built from 4 weeks of sleepless nights, many MANY cups of coffee, and the support of amazing TAs (and teammates!). We named our robot CHONKY.\nThe challenge was to build a treasure-hunting robot completely from scratch that could recover lost treasures from temple ruins. To do so, the robot would need to follow tape along a ramp, cross a 6” chicken wire gap, differentiate and follow infrared signals, and pick up irregularly shaped treasure statues positioned on 2” pedestals - all in under 2 minutes.\nOur Design # After many long meetings in the basement of the UBC Hebb building, we eventually settled on 3 DOF robotic arm design with rear-wheel drive. Here is a quick recap of CHONKY\u0026rsquo;s evolution (music to come).\nOn the mechanical side, we had an arm that consisted of 3 independent joints, encoded using potentiometers and DC motors to provide position feedback and reinforced with high gear ratios (eg. 40:1) to withstand heavy loading. Our chassis was primarily cut from hardboard, and our servo-actuated claw was wrapped with rubber bands to provide better grasp on oddly shaped objects.\nTo breathe life into our mechanical systems, our PCB stacks consisted of six H-bridge and optically-isolated servo circuits to control our drive and arm motors, as well as a five reflectance sensor and three infrared bandpass circuits for tape following and infrared navigation. All wires were intentionally shielded to minimize electrical noise and interfaced with PCBs using JST connectors.\nMy contributions were mostly on the electrical and software end of the project. I helped breadboard the initial IR filtration and tape-following circuits, soldered the power distribution boards, and designed the architecture for our software system.\nSoftware Architecture # The entirety of our codebase was written in C++ using the Arduino framework, and flashed onto a STM32 Blue Pill microcontroller. To make our codebase as modular and easy-to-test as possible, we decided to use a finite state machine to organize the control logic and packed lower-level functionalities into smaller driver modules.\nSoon enough, we realized that with 15 sensors and 9 motors, we were running out of I/O pins on a single Bluepill. To pivot, we took inspiration from some upper years who had competed in the 2018 competition ( Order66) to use two Bluepills and establish a master-slave communication protocol. While the master Bluepill was responsible for detecting treasures and actuating the arm, the slave Bluepill was in charge of all things drive and navigation related.\nYou can find our source code here. One of the most challenging tasks I faced was getting our PID for tape and IR following to work. Despite days of tuning our P, I, and D values, the mechanical response to our software was still super laggy and not improving. Eventually, we realized the problem was not in our software, but rather an issue with our motors and H-bridge circuits. Because how heavy CHONKY was, it turned out the motors could not supply enough torque below a certain speed. This was what caused the jerking-swaying motion in our PID. We also realized that we needed to decrease the capcitance value across the H-bridge so that the motor could discharge faster and change speeds faster.\nHere is a snippet of our PID code:\n/** * @file PID.cpp * @brief Class implementation for the PID feedback-control */ // Get reflectance sensor readings leftReading = analogRead(LEFT_TAPE_SENSOR); centreReading = analogRead(CENTER_TAPE_SENSOR); rightReading = analogRead(RIGHT_TAPE_SENSOR); // Display readings #ifndef COMP_MODE display-\u0026gt;write(10, \u0026#34;Left Reading:\u0026#34; + std::to_string(leftReading)); display-\u0026gt;write(20, \u0026#34;Centre Reading:\u0026#34; + std::to_string(centreReading)); display-\u0026gt;write(30, \u0026#34;Right Reading:\u0026#34; + std::to_string(rightReading)); #endif // Get tape error bool leftOnWhite = sensorOnWhite(leftReading, TAPE_WHITE_THRESHOLD); bool centreOnWhite = sensorOnWhite(centreReading, TAPE_WHITE_THRESHOLD); bool rightOnWhite = sensorOnWhite(rightReading, TAPE_WHITE_THRESHOLD); error = getTapeError(leftOnWhite, centreOnWhite, rightOnWhite); P = error; I += error; D = error - lastError; lastError = error; // (+) modMotorSpeed = tilting right = correct to the left // (-) modMotorSpeed = tilting left = correct to the right int modMotorSpeed = P*KP + I*KI + D*KD; int leftMotorSpeed = motorSpeed - modMotorSpeed; int rightMotorSpeed = motorSpeed + modMotorSpeed; // Set new motor speeds leftMotor-\u0026gt;setSpeed(leftMotorSpeed); rightMotor-\u0026gt;setSpeed(rightMotorSpeed); Again, shoutout to my team (Asvin, Farhan, and Adarsh) for being the best teammates I could\u0026rsquo;ve asked for and to our favorite TA, Rudi, for being in the trenches with us the entire way.\n","date":"1 January 0001","permalink":"/projects/chonky/","section":"Projects","summary":"A treasure-hunting robot that can detect obstacles, retrieve treasures, and navigate autonomously.","title":"CHONKY"},{"content":"","date":"1 January 0001","permalink":"/tags/cohere-llm-api/","section":"Tags","summary":"","title":"Cohere LLM API"},{"content":"","date":"1 January 0001","permalink":"/tags/convolution-neural-network/","section":"Tags","summary":"","title":"Convolution Neural Network"},{"content":"","date":"1 January 0001","permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker"},{"content":" What Is It # EduSphere is an interactive AR/VR language learning VisionOS application designed for the new Apple Vision Pro. It contains three fully developed features: a 3D popup game, a multi-lingual chatbot, and an immersive learning environment. This was our project submission for the Hack the North 2023 at UWaterloo, where we were selected as a finalist.\nHow We Built It # We built the VisionOS app using the Beta development kit for the Apple Vision Pro. The front-end and AR/VR components were made using Swift, SwiftUI, Alamofire, RealityKit, and concurrent MVVM design architecture. We stored our 3D models in Google Cloud Bucket Storage, with their corresponding metadata on CockroachDB.\nOur back-end features various scripts involving Python, SQL, Cohere LLMs, and Google Translation AI to allow for real-time text translation and conversing. I used the googletrans python library to translate text and generated chatbot responses to user prompts using the Cohere API. To connect our front-end with the back-end and allow HTTP get and post requests, we developed REST APIs in Flask to access each of our endpoints.\nThis was my first time working with Flask and building APIs so I found it super cool and also a lot easier than I\u0026rsquo;d imagined! Here are some of the APIs I created:\n# Example: http://127.0.0.1:5000/translate?word=hello\u0026amp;src=english\u0026amp;dest=chinese%20(simplified) @app.route(\u0026#39;/translate\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def get_translation(): word = request.args.get(\u0026#39;word\u0026#39;) src = request.args.get(\u0026#39;src\u0026#39;) dest = request.args.get(\u0026#39;dest\u0026#39;) translation = translate.get_translation(word, src, dest) jsonOutput = {\u0026#34;translation\u0026#34;: translation} return jsonOutput # Example: http://127.0.0.1:5000/languages @app.route(\u0026#39;/languages\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def get_languages(): return jsonify(translate.get_all_languages()) # Example: http://127.0.0.1:5000/chatbot-query?msg=have%20a%20conversation%20with%20me%20in%20french,%20and%20subtely%20give%20me%20feedback%20on%20my%20responses @app.route(\u0026#39;/chatbot-query\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def chatbot_query(): msg = request.args.get(\u0026#39;msg\u0026#39;) ans = chatbot.get_response(msg, convo_history) # Add message and answer to the chat history user_message = {\u0026#34;user_name\u0026#34;: \u0026#34;User\u0026#34;, \u0026#34;text\u0026#34;: msg} bot_message = {\u0026#34;user_name\u0026#34;: \u0026#34;Chatbot\u0026#34;, \u0026#34;text\u0026#34;: ans} convo_history.append(user_message) convo_history.append(bot_message) jsonOutput = {\u0026#34;reply\u0026#34;: ans} return jsonify(jsonOutput) You can find our source code here and our DevPost here. ","date":"1 January 0001","permalink":"/projects/edusphere/","section":"Projects","summary":"An AR language learning game submitted for Hack the North 2023, selected as one of twelve finalist projects.","title":"EduSphere"},{"content":"","date":"1 January 0001","permalink":"/tags/flask/","section":"Tags","summary":"","title":"Flask"},{"content":"","date":"1 January 0001","permalink":"/tags/google-cloud-translation-api/","section":"Tags","summary":"","title":"Google Cloud Translation API"},{"content":"","date":"1 January 0001","permalink":"/tags/leaflet/","section":"Tags","summary":"","title":"Leaflet"},{"content":"","date":"1 January 0001","permalink":"/tags/opencv/","section":"Tags","summary":"","title":"OpenCV"},{"content":"","date":"1 January 0001","permalink":"/tags/openstreetmap/","section":"Tags","summary":"","title":"OpenStreetMap"},{"content":"","date":"1 January 0001","permalink":"/tags/pid-control/","section":"Tags","summary":"","title":"PID Control"},{"content":"","date":"1 January 0001","permalink":"/tags/platformio/","section":"Tags","summary":"","title":"PlatformIO"},{"content":"","date":"1 January 0001","permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"","date":"1 January 0001","permalink":"/tags/python/","section":"Tags","summary":"","title":"Python"},{"content":"","date":"1 January 0001","permalink":"/tags/redis/","section":"Tags","summary":"","title":"Redis"},{"content":"","date":"1 January 0001","permalink":"/tags/reinforcement-learning/","section":"Tags","summary":"","title":"Reinforcement Learning"},{"content":"","date":"1 January 0001","permalink":"/tags/rest-apis/","section":"Tags","summary":"","title":"REST APIs"},{"content":"","date":"1 January 0001","permalink":"/tags/ros/","section":"Tags","summary":"","title":"ROS"},{"content":" What Is It # To be added ","date":"1 January 0001","permalink":"/projects/self-driving-ai-car/","section":"Projects","summary":"A self-driving virtual robot that uses deep learning and computer vision to classify license plates and navigate roads.","title":"Self-Driving AI Car"},{"content":"","date":"1 January 0001","permalink":"/tags/soldering/","section":"Tags","summary":"","title":"Soldering"},{"content":"","date":"1 January 0001","permalink":"/tags/stm32-microcontroller/","section":"Tags","summary":"","title":"STM32 Microcontroller"},{"content":"","date":"1 January 0001","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"1 January 0001","permalink":"/tags/tensorflow/","section":"Tags","summary":"","title":"TensorFlow"},{"content":" What Is It # To be added ","date":"1 January 0001","permalink":"/projects/aerodesign/","section":"Projects","summary":"A student design team that designs and builds fixed-wing aircraft to compete in the annual SAE Aero Design competition.","title":"UBC AeroDesign"},{"content":"","date":"1 January 0001","permalink":"/tags/zmq/","section":"Tags","summary":"","title":"ZMQ"}]